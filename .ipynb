{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpqq/5TegxU3seLR/S4nzi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tebzzz/algo/blob/main/.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLfdtbb96MGF"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from ib_insync import *\n",
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "import pytz\n",
        "import ntplib\n",
        "import time\n",
        "import ccxt\n",
        "import ccxt.pro as ccxtpro\n",
        "import sqlalchemy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os.path import exists\n",
        "from pykalman import KalmanFilter\n",
        "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
        "import requests\n",
        "from loguru import logger\n",
        "import json\n",
        "import concurrent.futures\n",
        "from sqlalchemy import MetaData, Table"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#modeling\n",
        "modelling_bar_size = '1 day'\n",
        "modelling_duration = '1 Y'\n",
        "\n",
        "#equity trading\n",
        "bar_size_equity = '1 hour'\n",
        "duration_equity = '1 Y'\n",
        "\n",
        "use_websockets = True\n",
        "periods_per_day = 1\n",
        "trade_status = None #Variable that tells us if we are opening or closing a trade.\n",
        "ohlcv = True\n",
        "crypto = False #true/false\n",
        "\n",
        "#signals\n",
        "volume_signal = True\n",
        "vol_notrade_multiple = 5\n",
        "\n",
        "global_data = pd.DataFrame()\n",
        "position_ratios, current_state, last_pos = {} , None, None #Can be manually changed to change the state when restarting a script.\n",
        "internal_id = 100000\n",
        "\n",
        "entry_sigma = 3 #the standard deviation multiplyer we are using for bollinger bands\n",
        "exit_sigma = 4\n",
        "use_stoploss = True\n",
        "total_order_value = 10 #the current value of our orders\n",
        "\n",
        "lookback = 50\n",
        "average_type = 'sma' #***this might be the cause of our problems\n",
        "band_type = 'bollinger'\n",
        "bollinger_type = 'sma'\n",
        "bollinger_vol_exp = 1\n",
        "\n",
        "#stop settings\n",
        "max_loss = -0.03\n",
        "break_on_loss = True\n",
        "spread_type = 'log'\n",
        "\n",
        "#connects to CloudSQL postgres\n",
        "username = 'postgres'\n",
        "password = 'password123'\n",
        "host = '34.69.230.27'\n",
        "port = '5432'\n",
        "database = 'postgres'\n",
        "\n",
        "db_url = 'postgresql+psycopg2://{}:{}@{}:{}/{}'.format(\n",
        "    username, password, host, port, database)\n",
        "\n",
        "engine = sqlalchemy.create_engine(db_url) #,connect_args={'options': '-c lock_timeout=3000 -c statement_timeout=5000'})\n",
        "cloud = engine.connect()\n",
        "meta = MetaData()\n",
        "\n",
        "#connecting to ntp server for time\n",
        "c = ntplib.NTPClient()\n",
        "\n",
        "if crypto == False:\n",
        "\n",
        "    #connecting to interactive brokers\n",
        "    num = round(random.random()*100)\n",
        "    gateway_port = 4001\n",
        "    ib = IB()\n",
        "    ib.connect(host='127.0.0.1', port=gateway_port, clientId=num)\n",
        "\n",
        "elif crypto == True:\n",
        "\n",
        "#instantiating binance class object\n",
        "    log_name = 'rum'\n",
        "\n",
        "    logger.add(\n",
        "        log_name,\n",
        "        level=\"INFO\",\n",
        "        format=\"{time} {level} {message}\",\n",
        "        rotation=\"00:00\",  # each day at 00:00 we create a new log file\n",
        "        compression=\"zip\",  # archive old log files to save space\n",
        "        retention=\"3 days\",  # delete logs after 30 days\n",
        "        serialize=True,  # json format of logs\n",
        "    )\n",
        "\n",
        "    #connecting to exchange\n",
        "    exchange_id = 'binanceusdm'\n",
        "    exchange_class = getattr(ccxt, exchange_id)\n",
        "    exchange = exchange_class({\n",
        "        'apiKey': 'rSw15gwfuc3USRqLBi4mm5qQ5CP5HfdElUXN9tHC6222j64FpHtZ0T7E8MKncFC9',\n",
        "        'secret': 'EqIuEQSJOI8CP4Ge5XhxzQInZ4KTRDRVSOmMspl9guUZGyxVISwZ4YsaWfJrD0kA',\n",
        "        'enableRateLimit': True,\n",
        "    })"
      ],
      "metadata": {
        "id": "fAx1USXL6P6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reconnect():\n",
        "    logger.info('Connection was likely disconnected. Pausing for 10 minutes and then will attempt to reconnect.')\n",
        "    now = market_time()\n",
        "    logger.info('The current time is ' + str(now))\n",
        "    ib.sleep(600)\n",
        "    logger.info(\"Attempting to reconnect\")\n",
        "    try:\n",
        "        num = round(random.random()*100)\n",
        "        ib.connect(host='127.0.0.1', port=gateway_port, clientId=num)\n",
        "        ib.sleep(5)\n",
        "    except Exception as e:\n",
        "        logger.info(e)"
      ],
      "metadata": {
        "id": "7igvkG2d6jlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all the arguments from config.json\n",
        "def read_arguments_from_file(file_name):\n",
        "    with open(file_name, 'r') as json_arguments:\n",
        "        arguments = json.load(json_arguments)  # read all the arguments from file (from config.json for example)\n",
        "        return arguments\n",
        "\n",
        "# send arguments to the function and start it multiple times using threads\n",
        "def create_threads(arguments, function_name):\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=len(arguments)) as executor:\n",
        "        executor.map(lambda f: function_name(**f), arguments)\n",
        "\n",
        "#functions for equities (likely not complete)\n",
        "def check_status_func(current_state, quantity_a, quantity_b):\n",
        "    if current_state == None:\n",
        "        if quantity_a == 0 and quantity_b == 0:\n",
        "            return True\n",
        "    elif current_state.lower() == 'long':\n",
        "        if quantity_a > quantity_b:\n",
        "            return True\n",
        "    elif current_state.lower() == 'short':\n",
        "        if quantity_a < quantity_b:\n",
        "            return True\n",
        "    return False\n",
        "#General Functions"
      ],
      "metadata": {
        "id": "PDY2-KfB6lKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_current_state(data):\n",
        "\n",
        "    pair_number = data['pair_number']\n",
        "\n",
        "    res = cloud.execute(\"SELECT current_status FROM current_data WHERE pair_number = \" + str(pair_number)).one()[0]\n",
        "    if res != None:\n",
        "        res = res.lower()\n",
        "    if res == 'none' or res == None:\n",
        "        return None\n",
        "    elif res == 'long' or res == 'short':\n",
        "        return res\n",
        "    else:\n",
        "        logger.info('Status is not in the correct program, shutting down script')\n",
        "        print(break123)"
      ],
      "metadata": {
        "id": "Y1c3BHP06oDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def round_list(list, decimals): #can only run lists of floating point numbers through this\n",
        "    res = []\n",
        "    for i in range(len(list)):\n",
        "        num = round(list[i], decimals)\n",
        "        res.append(num)\n",
        "    return res"
      ],
      "metadata": {
        "id": "Gt5l-UC_6pbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_quantities(tickers, global_data, data, position_ratios):\n",
        "\n",
        "    ticker_quantities = {}\n",
        "    mkt_data = exchange.loadMarkets()\n",
        "\n",
        "    step_sizes = {}\n",
        "    min_qty = {}\n",
        "\n",
        "    total_dollar_value = data['total_order_value']\n",
        "\n",
        "    prices = {} #Figure out how to get prices from global_data\n",
        "    for t in tickers:\n",
        "        prices[t] = global_data['{t}']\n",
        "\n",
        "    total_val = 0\n",
        "\n",
        "    for p in position_ratios:\n",
        "        total_val += position_ratios[p]*prices[p]\n",
        "\n",
        "    multiplier = total_dollar_value/total_val #muliplier of the position ratios.\n",
        "    ticker_quantities = position_ratios*multiplier #how do we multiple by all values?\n",
        "\n",
        "    #getting step sizes and minimum quantities\n",
        "    for t in tickers:\n",
        "        step_sizes[t] = float(mkt_data[t]['info']['filters'][1]['stepSize'])\n",
        "        min_qty[t] = mkt_data[t]['limits']['amount']['min']\n",
        "\n",
        "    #ensure we are at the most recent step size and above the minimum\n",
        "    for a in min_qty:\n",
        "        if ticker_quantities[a] < min_qty[a]:\n",
        "            ticker_quantities[a] = min_qty[a]\n",
        "        else:\n",
        "            ticker_quantities[a] = ticker_quantities[a]-(ticker_quantities[a]%step_sizes[a])\n",
        "\n",
        "    return ticker_quantities"
      ],
      "metadata": {
        "id": "J5_zUKao6rzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_tickers(tickers):\n",
        "    formatted_tickers = []\n",
        "\n",
        "    for t in tickers:\n",
        "        if t[-5:] == '/USDT':\n",
        "            formatted_tickers.append(t.split('/')[0] + 'USDT')\n",
        "        elif t[-5:] == '/BUSD':\n",
        "            formatted_tickers.append(t.split('/')[0] + 'BUSD')\n",
        "        else:\n",
        "            formatted_tickers.append(t)\n",
        "\n",
        "    return formatted_tickers"
      ],
      "metadata": {
        "id": "JkKPjf086so0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##pairs trading specific functions\n",
        "\n",
        "def set_positions_database(internal_id, tickers, ticker_quantities, prior_state, current_pos, data, stop=False): #***work on this one\n",
        "    pair_number = data['pair_number']\n",
        "\n",
        "    if internal_id == None:\n",
        "        internal_id = 300000\n",
        "\n",
        "    heartbeat = int(time.time()*1000)\n",
        "    formatted_tickers = format_tickers(tickers)\n",
        "\n",
        "    res = cloud.execute(\"SELECT * FROM positions WHERE pair_number=\" + str(pair_number)).all()[0]\n",
        "    current_positions = {}\n",
        "\n",
        "    res_tickers = cloud.execute(\"SELECT * FROM tickers WHERE pair_number=\" + str(pair_number)).all()[0]\n",
        "\n",
        "    #need to get current positions here from res\n",
        "    for i in range(len(tickers)):\n",
        "        current_positions[tickers[i]] == res[0+1]\n",
        "\n",
        "    final_quantities = {}\n",
        "    ticker_deltas = {}\n",
        "\n",
        "    if current_pos == None:\n",
        "\n",
        "        open_close = 'CLOSE'\n",
        "\n",
        "        if prior_state == None:\n",
        "\n",
        "            for ticker in tickers:\n",
        "\n",
        "                if current_positions[ticker] != 0:\n",
        "\n",
        "                    ticker_delta = current_positions[ticker]*-1 #make sure this logic makes sense\n",
        "                    cloud.execute(\"INSERT into trade_data_queue (pair_number, ticker, quantity, open_close, shares_remaining, timestamp, internal_id) values (\" + str(pair_number) + \",'\" + str(ticker)+ \"',\" + str(ticker1_delta) + \",'\" + open_close + \"', \" + str(ticker_delta) + \",\" + str(heartbeat) + \",\" + str(internal_id) + \")\")\n",
        "                    logger.info(f\"Inserting into trade_data_queue. Pair number: {pair_number} Ticker: {ticker} Ticker Delta: {ticker1_delta} Open/Close: {open_close} Timesatmp: {heartbeat} Internal Id: {internal_id}\")\n",
        "\n",
        "                cloud.execute(\"UPDATE positions SET ticker1='\" + str(ticker) + \"', pos_change_time = \" + str(heartbeat) + \" WHERE pair_number=\" + str(pair_number)) #*** this likely needs to be adjusted\n",
        "                logger.info(f\"Updating positions pair number {pair_number} {ticker} positions set to zero at timestamp {heartbeat}\")\n",
        "\n",
        "\n",
        "        elif prior_state.lower() == 'long':\n",
        "\n",
        "            ticker_deltas = final_quantities\n",
        "\n",
        "        elif prior_state.lower() == 'short':\n",
        "\n",
        "            ticker_deltas = final_quantities*-1\n",
        "\n",
        "    elif current_pos.lower() == 'long':\n",
        "\n",
        "        final_quantities = ticker_quantities\n",
        "        ticker_deltas = current_positions\n",
        "\n",
        "        open_close = 'OPEN'\n",
        "    elif current_pos.lower() == 'short':\n",
        "\n",
        "        final_quantities = ticker_quantities*-1\n",
        "        ticker_deltas = current_positions*-1\n",
        "\n",
        "        open_close = 'OPEN'\n",
        "\n",
        "    if ticker1_pos == None:\n",
        "        pass\n",
        "    else:\n",
        "        ticker1_pos = float(ticker1_pos)\n",
        "\n",
        "    if open_close == 'OPEN':\n",
        "        internal_id = str(pair_number) + str(heartbeat)[-5:]\n",
        "\n",
        "    for ticker in tickers:\n",
        "\n",
        "        if current_positions[ticker] == final_quantities[ticker]: #and ticker == ticker_curr_ticker: Keep this as a check to make sure we have the right ticker?\n",
        "            pass\n",
        "\n",
        "        else:\n",
        "            if current_positions[ticker] != final_quantities[ticker]:\n",
        "                cloud.execute(\"INSERT into trade_data_queue (pair_number, ticker, quantity, open_close, shares_remaining, timestamp, internal_id) values (\" + str(pair_number) + \",'\" + str(ticker)+ \"',\" + str(ticker_delta) + \",'\" + open_close + \"', \" + str(ticker_delta) + \",\" + str(heartbeat) + \",\" + str(internal_id)+ \")\")\n",
        "                logger.info(f\"Inserting into trade_data_queue. Pair number: {pair_number} Ticker: {ticker} Ticker Delta: {ticker1_delta} Open/Close: {open_close} Timesatmp: {heartbeat} Internal Id: {internal_id}\")\n",
        "\n",
        "            cloud.execute(\"UPDATE positions SET ticker=\" + str(final_quantities[ticker]) + \" WHERE pair_number=\" + str(pair_number))\n",
        "            cloud.execute(\"UPDATE tickers...\")\n",
        "            #*** set ticker position\n",
        "            logger.info(f\"Updating positions setting {ticker} quantity to {final_quantities[ticker]} under pair {pair_number}\")\n",
        "\n",
        "\n",
        "    cloud.execute(\"UPDATE positions SET pos_change_time = \" + str(heartbeat) + \" WHERE pair_number=\" + str(pair_number))\n",
        "\n",
        "    return internal_id"
      ],
      "metadata": {
        "id": "niceLm4f6ucd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_positions(z, moving_avg, upper_band, lower_band, reset_flag, current_pos='short'):\n",
        "\n",
        "    if current_pos == None:\n",
        "        reset_flag = False\n",
        "        if z > upper_band:\n",
        "            trade_status = 'open'\n",
        "            return 'short', reset_flag, trade_status\n",
        "        elif z < lower_band:\n",
        "            trade_status = 'open'\n",
        "            return 'long', reset_flag, trade_status\n",
        "        else:\n",
        "            return None, reset_flag, None\n",
        "\n",
        "    elif current_pos.lower() == 'long':\n",
        "        if z >= moving_avg:\n",
        "            reset_flag = False\n",
        "            trade_status = None\n",
        "            return None, reset_flag, trade_status\n",
        "        elif z < moving_avg:\n",
        "            return 'long', reset_flag, None\n",
        "\n",
        "    elif current_pos.lower() == 'short':\n",
        "        if z <= moving_avg:\n",
        "            reset_flag = False\n",
        "            trade_status = None\n",
        "            return None, reset_flag, trade_status\n",
        "        elif z > moving_avg:\n",
        "            return 'short', reset_flag, None\n"
      ],
      "metadata": {
        "id": "pI2BCnaH6yIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean Rev math specific functions\n",
        "def get_spread(position_ratios, prices = None, global_data = None):\n",
        "    #get prices from global data\n",
        "    if not prices:\n",
        "        prices = {}\n",
        "        for t in position_ratios:\n",
        "            prices[t] = global_data[{t}]\n",
        "\n",
        "    prices_df = pd.DataFrame(prices)\n",
        "    #get spread over time (position ratios*prices)\n",
        "    spread = (prices_df.multiply(position_ratios, axis=1)).sum(axis=1)\n",
        "\n",
        "    return spread"
      ],
      "metadata": {
        "id": "39xkJqVP6y3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bollinger_bands(zscore, sigma):\n",
        "    zscore_df = pd.DataFrame(zscore)\n",
        "    moving_avg = get_moving_avg(zscore)\n",
        "    span = lookback\n",
        "    if bollinger_type == 'ema':\n",
        "        std = zscore_df.ewm(span).std()\n",
        "    else:\n",
        "        std = zscore_df.rolling(lookback).std()\n",
        "    bollinger_up = moving_avg + std**bollinger_vol_exp * sigma\n",
        "    bollinger_down = moving_avg - std**bollinger_vol_exp * sigma\n",
        "\n",
        "    return bollinger_up, bollinger_down"
      ],
      "metadata": {
        "id": "jTbr4GiF61O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bands(zscore, sigma=None):\n",
        "    if sigma == None:\n",
        "        sigma = entry_sigma\n",
        "    if band_type == 'bollinger':\n",
        "        upper_band, lower_band = get_bollinger_bands(zscore, sigma)\n",
        "    # elif band_type == 'keltner':\n",
        "    #     upper_band, lower_band = get_keltner_channel(zscore) #will need additional information\n",
        "    return upper_band, lower_band"
      ],
      "metadata": {
        "id": "bRwiYP8L62cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_kalman_filter(zscore):\n",
        "\n",
        "    res = []\n",
        "    zscore = zscore[lookback*2-2:]\n",
        "\n",
        "    kf = KalmanFilter(transition_matrices = [1],    # The value for At. It is a random walk so is set to 1.0\n",
        "                  observation_matrices = [1],   # The value for Ht.\n",
        "                  initial_state_mean = 0,       # Any initial value. It will converge to the true state value.\n",
        "                  initial_state_covariance = 1, # Sigma value for the Qt in Equation (1) the Gaussian distribution\n",
        "                  observation_covariance=1,     # Sigma value for the Rt in Equation (2) the Gaussian distribution\n",
        "                  transition_covariance=.01)    # A small turbulence in the random walk parameter 1.0\n",
        "\n",
        "    # Get the Kalman smoothing\n",
        "    state_means, _ = kf.filter(zscore)\n",
        "\n",
        "    for num in state_means:\n",
        "        res.append(num[0])\n",
        "\n",
        "    return [0]*(lookback*2-2) + res"
      ],
      "metadata": {
        "id": "fiQpwHRH63r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_moving_avg(prices, override=None):\n",
        "    prices_df = pd.DataFrame(prices)\n",
        "    if not override:\n",
        "        type = average_type\n",
        "    else:\n",
        "        type = override\n",
        "    if type =='sma':\n",
        "        ma_df = prices_df.rolling(lookback).mean()\n",
        "    elif type == 'ema':\n",
        "        span = lookback\n",
        "        ma_df = prices_df.ewm(span).mean()\n",
        "    elif type == 'kalman':\n",
        "        ma_df = get_kalman_filter(prices)\n",
        "        ma_df = pd.DataFrame(ma_df)\n",
        "    return ma_df"
      ],
      "metadata": {
        "id": "fwGDk98W65lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_zscore(spread):\n",
        "    spread_df = pd.DataFrame(spread)\n",
        "    moving_avg_df = get_moving_avg(spread, override='sma')\n",
        "    std_df = spread_df.rolling(lookback).std()\n",
        "    zscore = []\n",
        "    for i in range(len(spread)):\n",
        "        spd = float(spread_df.iloc[i])\n",
        "        mva = float(moving_avg_df.iloc[i])\n",
        "        std1 = float(std_df.iloc[i])\n",
        "        zscore.append((spd-mva)/std1)\n",
        "    return zscore"
      ],
      "metadata": {
        "id": "JFiZgNk567TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(spread=None, global_data=None, position_ratios=None):\n",
        "    print(len(spread))\n",
        "    # if not spread:\n",
        "    #     spread = get_spread(position_ratios, global_data=global_data)\n",
        "\n",
        "    zscore = get_zscore(spread)\n",
        "    band_up_df, band_down_df = get_bands(zscore)\n",
        "    z_moving_avg_df = get_moving_avg(zscore) #This can be easily changed to a kalman filter to implement within the code\n",
        "\n",
        "    if math.isnan(z_moving_avg_df.iloc[-1]) == True:\n",
        "        logger.error('The duration we are looking back at is likely not longer than the lookback period! Fix to get correct functionality!')\n",
        "\n",
        "    return zscore, band_up_df[0].tolist(), band_down_df[0].tolist(), z_moving_avg_df[0].tolist()\n",
        "\n",
        "#Mean reversion specific functions"
      ],
      "metadata": {
        "id": "w5k392UZ8apS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_data(data, tickers, current_state, global_data):\n",
        "\n",
        "        pair_number = data['pair_number']\n",
        "        bar_size = data['bar_size']\n",
        "\n",
        "        curr_time = int(time.time()*1000)\n",
        "\n",
        "        #Get quant data\n",
        "\n",
        "        latest_time, current_z, current_average, current_upper_band, current_lower_band = global_data['Time'].iloc[0], global_data['Zscore'].iloc[0], global_data['Moving Average'].iloc[0], global_data['Upper Band'].iloc[0], global_data['Lower Band'].iloc[0]# we are likely aligning the wrong thing with the wrong times\n",
        "        prices = global_data['Ticker 1 Price'].iloc[0]\n",
        "        latest_spread = global_data['Spread'].iloc[0]\n",
        "        #latest_volume_a, latest_volume_b = global_data['Volume A'].iloc[0], global_data['Volume B'].iloc[0]\n",
        "\n",
        "        #Log total_equity for that pair\n",
        "\n",
        "        res = cloud.execute(\"SELECT total_pl from current_data WHERE pair_number=\" + str(pair_number))\n",
        "        current_equity = res.one()[0]\n",
        "        if current_equity == None:\n",
        "            current_equity = 0\n",
        "\n",
        "        table_name = 'pair_data_' + str(pair_number)\n",
        "\n",
        "        #Write to pair Data, may be moved to display.py later\n",
        "\n",
        "        latest_recorded_time = int(cloud.execute(\"SELECT timestamp from \" + table_name + \" ORDER BY timestamp desc\").all()[0][0])\n",
        "        if latest_recorded_time != latest_time:\n",
        "            cloud.execute(\"INSERT INTO \" + table_name + \" (timestamp, zscore, upper_band, lower_band ,moving_average, spread, prices_a, prices_b, volume_a, volume_b, equity) VALUES (\" + str(latest_time) + \",\" + str(current_z) + \",\" + str(current_upper_band) + \",\" + str(current_lower_band) + \",\" + str(current_average) + \",\" + str(latest_spread) + \",\" + str(current_equity) + \")\")\n",
        "        else:\n",
        "            cloud.execute(\"UPDATE \" + table_name + \" SET zscore=\" + str(current_z) + \",upper_band=\" + str(current_upper_band) +  \",lower_band=\" + str(current_lower_band) + \",moving_average= \" + str(current_average)+ \" ,spread=\" + str(latest_spread) + \" ,prices_a=\" +  \", volume_a=\" + str( \",equity= \" + str(current_equity) + \" WHERE timestamp=\" + str(int(latest_recorded_time))))\n",
        "\n",
        "        #Write to current data\n",
        "\n",
        "        tickers = [str(a).upper() for a in tickers]\n",
        "\n",
        "        cloud.execute(f\"UPDATE current_data SET bar_size = '{bar_size}', lookback = {str(lookback)}, current_z = {str(current_z)}, upper_band = {str(current_upper_band)}, lower_band = {str(current_lower_band)}, moving_average = {str(current_average)}, current_status = '{str(current_state)}',heartbeat = {str(curr_time)},price_a={str(latest_price_a)},price_b={str(latest_price_b)},spread={str(latest_spread)} WHERE pair_number = {str(pair_number)}\")\n",
        "        cloud.execute(f\"UPDATE positions SET script_update_time = {str(curr_time)} WHERE pair_number={str(pair_number)}\")\n"
      ],
      "metadata": {
        "id": "pmd3V3Ts8b0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_exit_conditions(internal_id, global_data, tickers, ticker_quantities, current_status, data, percent_stop=False, totalpl_stop=False, use_crypto=False): #return true if the conditions pass, return false if no longer cointegrated or we are outside of standard deviation or spread parameters\n",
        "    #internal id cannot be none\n",
        "    pair_number = data['pair_number']\n",
        "    bar_size = data['bar_size']\n",
        "\n",
        "    total_order_value = data['total_order_value']\n",
        "    max_loss = data['max_loss']\n",
        "    break_on_loss = data['break_on_loss']\n",
        "\n",
        "    permitted_loss = 0.05\n",
        "    total_capital = total_order_value*2\n",
        "\n",
        "    adj_tickers = format_tickers(tickers)\n",
        "\n",
        "    if totalpl_stop == True:\n",
        "        res = cloud.execute(\"SELECT total_pl FROM current_data where pair_number = \" + str(pair_number))\n",
        "        pl = float(res.all()[0][0])\n",
        "\n",
        "        if pl < total_capital*(permitted_loss)*-1:\n",
        "            logger.info('We are below the stop loss for percent of capital lost. Closing position and shutting down script!')\n",
        "\n",
        "            trade_status = None\n",
        "            internal_id = set_positions_database(internal_id, tickers, 0,0,None, None,data,use_crypto=use_crypto,stop=True) #If there is an error check the prior state.\n",
        "            print(break123)\n",
        "\n",
        "    #trade goes below a % loss\n",
        "    if percent_stop == True:\n",
        "        res = cloud.execute(\"SELECT * FROM prices WHERE pair_number=\" + str(pair_number)).fetchall()[0]\n",
        "        open_prices = {}\n",
        "\n",
        "        if current_status == None or current_status == 'None':\n",
        "            return\n",
        "\n",
        "        #get open prices from the sql table\n",
        "        for price in res:\n",
        "            pass\n",
        "\n",
        "        current_prices = {}\n",
        "        for t in tickers:\n",
        "            current_prices[t] = get_prices_websocket(t, bar_size, 1, ohclv=False, return_all_data=True, use_crypto=use_crypto)[0][4]\n",
        "\n",
        "        if len(price) == 0: #if there are no values above zero.\n",
        "            return\n",
        "\n",
        "        if current_status.lower() == 'long':\n",
        "            current_trade_pl = 0\n",
        "            for t in tickers:\n",
        "                current_trade_pl += ticker_quantities[t]*(current_prices[t]-price[t])\n",
        "\n",
        "        elif current_status.lower() == 'short':\n",
        "            current_trade_pl = 0\n",
        "            for t in tickers:\n",
        "                current_trade_pl += ticker_quantities[t]*(current_prices[t]-price[t])\n",
        "\n",
        "    if current_trade_pl < total_capital*(max_loss):\n",
        "        logger.info('The current trade p/l is:' + str(current_trade_pl))\n",
        "        logger.info('The total capital*max loss is:' + str(total_capital*(max_loss)))\n",
        "\n",
        "        if break_on_loss == True:\n",
        "\n",
        "            trade_status = None\n",
        "            logger.info('We are below the stop loss for percent of capital lost, shutting down script!')\n",
        "            open_close = 'CLOSE'\n",
        "\n",
        "            #ticker deltas\n",
        "            ticker_deltas = {}\n",
        "            ticker1_delta = float(cloud.execute(f\"SELECT ticker1_pos FROM positions WHERE pair_number={pair_number}\").fetchone()[0])\n",
        "\n",
        "            heartbeat = int(time.time()*1000)\n",
        "\n",
        "            for ticker in tickers:\n",
        "\n",
        "                cloud.execute(f\"INSERT into trade_data_queue (pair_number, ticker, quantity, open_close, shares_remaining, timestamp, internal_id) values ({str(pair_number)},'{str(ticker)}',{str(ticker_deltas[ticker])},'{open_close}',{str(ticker_deltas[ticker])},{str(heartbeat)},{str(internal_id)})\")\n",
        "                logger.info(f\"Inserting into trade_data_queue. Pair number: {pair_number} Ticker: {ticker} Ticker Delta: {ticker1_delta} Open/Close: {open_close} Timesatmp: {heartbeat} Internal Id: {internal_id}\")\n",
        "\n",
        "            cloud.execute(f\"UPDATE current_data SET current_status='None' WHERE pair_number={pair_number}\")\n",
        "            cloud.execute(f\"UPDATE positions SET stop_flag=True WHERE pair_number={str(pair_number)}\")\n",
        "\n",
        "            time.sleep(10)\n",
        "\n",
        "            set_positions_database(internal_id, tickers, 0,0,None, None,data,use_crypto=use_crypto,stop=True)\n",
        "            internal_id = 100000\n",
        "            print(break123)\n",
        "\n",
        "        elif break_on_loss == False:\n",
        "            reset_flag = True\n",
        "            trade_status = None\n",
        "            logger.info('We hit the stop loss for this position, resetting. ')\n",
        "\n",
        "            open_close = 'CLOSE'\n",
        "\n",
        "            ticker_deltas = {}\n",
        "            ticker1_delta = float(cloud.execute(f\"SELECT ticker1_pos FROM positions WHERE pair_number={pair_number}\").fetchone()[0])\n",
        "\n",
        "            heartbeat = int(time.time()*1000)\n",
        "\n",
        "            for ticker in tickers:\n",
        "\n",
        "                cloud.execute(f\"INSERT into trade_data_queue (pair_number, ticker, quantity, open_close, shares_remaining, timestamp, internal_id) values ({str(pair_number)},'{str(ticker)}',{str(ticker_deltas[ticker])},'{open_close}',{str(ticker_deltas[ticker])},{str(heartbeat)},{str(internal_id)})\")\n",
        "                logger.info(f\"Inserting into trade_data_queue. Pair number: {pair_number} Ticker: {ticker} Ticker Delta: {ticker1_delta} Open/Close: {open_close} Timesatmp: {heartbeat} Internal Id: {internal_id}\")\n",
        "\n",
        "            cloud.execute(f\"UPDATE positions SET stop_flag=True WHERE pair_number={str(pair_number)}\")\n",
        "            cloud.execute(f'UPDATE current_data SET current_status=Stop WHERE pair_number={pair_number}')\n",
        "\n",
        "            time.sleep(10)\n",
        "\n",
        "            set_positions_database(internal_id, tickers, 0,0,None, None,data,use_crypto=use_crypto,stop=True)\n",
        "            internal_id = 100000\n",
        "\n",
        "            return internal_id\n",
        "\n",
        "#websocket specific functions"
      ],
      "metadata": {
        "id": "_Yn8G7wW8eFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wait_for_tables(tickers, bar_size): #***this needs a slight amount of work\n",
        "    tables = []\n",
        "    all_tables_exist = False\n",
        "    tables_current = False\n",
        "\n",
        "    for t in tickers:\n",
        "        table = ('ohlcv_' + str(t) + '_' +  str(bar_size)).lower()\n",
        "        tables.append(table)\n",
        "\n",
        "    while all_tables_exist == False:\n",
        "        for table in tables:\n",
        "            price_ticker = None\n",
        "\n",
        "            try:\n",
        "                price = cloud.execute(\"SELECT close FROM \" + str(table) + \" ORDER BY timestamp DESC\").all()[0][0]\n",
        "                if type(price) == type(float(1.0)):\n",
        "                    price_ticker = price\n",
        "                else:\n",
        "                    logger.info(f\"{table} price not a float\")\n",
        "                    #do we need to break here?\n",
        "            except:\n",
        "                logger.info(f\"{table} has not been created yet!\")\n",
        "                time.sleep(10)\n",
        "                break\n",
        "\n",
        "        all_tables_exis = True\n",
        "\n",
        "    #ensure that both tables are close to the recent time (within an hour or so) to ensure that we aren't working off an old table.\n",
        "\n",
        "    logger.info('Tables all exist, checking dates!')\n",
        "\n",
        "    while tables_current == False:\n",
        "\n",
        "        current_time = int(time.time()*1000)\n",
        "        for table in tables:\n",
        "\n",
        "            last_time_table = cloud.execute(\"SELECT timestamp FROM \" + str(table) + \" ORDER BY timestamp DESC\").fetchone()[0]\n",
        "        try:\n",
        "            while last_time_table + (60*30*1000) < current_time:\n",
        "\n",
        "                current_time = int(time.time()*1000)\n",
        "                last_time_table1 = cloud.execute(\"SELECT timestamp FROM \" + str(table) + \" ORDER BY timestamp DESC\").fetchone()[0]\n",
        "                logger.info('Table dates are not recent. Ensure websockets.py is running properly!')\n",
        "                time.sleep(5)\n",
        "\n",
        "        except:\n",
        "            logger.info(\"Likely the table was recreated due to being old. Script will continue!\")\n",
        "            break\n",
        "\n",
        "        tables_current = True\n",
        "\n",
        "    logger.info('Tables are all up to date! Moving forward!')"
      ],
      "metadata": {
        "id": "zH8o1g7u8iDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_table(data, ticker, tables, base_table, bar_size, heartbeat):\n",
        "\n",
        "    pair_number = data['pair_number']\n",
        "\n",
        "    id = pair_number + random.randint(0,1000000)\n",
        "    table = (str(ticker) + '_' +  str(bar_size)).lower()\n",
        "    limit = 2000 #Might have to be changed if there is a super long lookback\n",
        "\n",
        "    if table in tables:\n",
        "        res = cloud.execute(\"SELECT * FROM \" + str(base_table) + \" WHERE ticker_name='\" + str(ticker.upper()) + \"' AND bar_size='\" + str(bar_size) + \"'\").all()\n",
        "        if len(res) == 1:\n",
        "            cloud.execute(\"UPDATE \" + str(base_table) + \" SET heartbeat=\"+ str(heartbeat) + \" WHERE ticker_name='\" + str(ticker) + \"' AND bar_size ='\" + str(bar_size) + \"'\") #update heartbeat\n",
        "        else:\n",
        "            try:\n",
        "                cloud.execute(\"DELETE FROM \"+ str(base_table) + \" WHERE ticker_name='\" + str(ticker.upper()) + \"' AND bar_size='\" + str(bar_size) + \"'\")\n",
        "            except:\n",
        "                pass\n",
        "            cloud.execute(\"DROP TABLE \" + str(table))\n",
        "\n",
        "            if base_table == 'price_websockets':\n",
        "                cloud.execute(\"INSERT INTO price_websockets (id, ticker_name, bar_size, heartbeat) VALUES (\" + str(id) + \",'\" + str(ticker.upper()) + \"','\" + str(bar_size) + \"',\" + str(heartbeat) + str(\")\"))\n",
        "            elif base_table == 'ohlcv_websockets':\n",
        "                cloud.execute(\"INSERT INTO ohlcv_websockets (id, ticker_name, bar_size, limits, heartbeat) VALUES (\" + str(id) + \",'\" + str(ticker.upper()) + \"','\" + str(bar_size) + \"',\" + str(limit) + \",\" + str(heartbeat) + str(\")\"))\n",
        "\n",
        "    else: #add to list\n",
        "        try:\n",
        "            cloud.execute(\"DELETE FROM \"+ str(base_table) + \" WHERE ticker_name='\" + str(ticker.upper()) + \"' AND bar_size='\" + str(bar_size) + \"'\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        if base_table == 'price_websockets':\n",
        "            cloud.execute(\"INSERT INTO price_websockets (id, ticker_name, bar_size, heartbeat) VALUES (\" + str(id) + \",'\" + str(ticker.upper()) + \"','\" + str(bar_size) + \"',\" + str(heartbeat) + str(\")\"))\n",
        "        elif base_table == 'ohlcv_websockets':\n",
        "            cloud.execute(\"INSERT INTO ohlcv_websockets (id, ticker_name, bar_size, limits, heartbeat) VALUES (\" + str(id) + \",'\" + str(ticker.upper()) + \"','\" + str(bar_size) + \"',\" + str(limit) + \",\" + str(heartbeat) + str(\")\"))\n"
      ],
      "metadata": {
        "id": "KYU1-C6P8kDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_websockets(data, tickers, bar_size, ohlcv=False):\n",
        "    heartbeat = int(time.time()*1000)\n",
        "\n",
        "    if ohlcv == True:\n",
        "        base_table = 'ohlcv_websockets'\n",
        "    else:\n",
        "        base_table = 'price_websockets'\n",
        "\n",
        "    #get list of all tables in postgres, check if tables exist\n",
        "    tables = pd.DataFrame(cloud.execute(\"SELECT table_name FROM information_schema.tables\"))\n",
        "    tables = tables['table_name'].values.tolist()\n",
        "\n",
        "    for t in tickers:\n",
        "        prepare_table(data, tickers[t], tables, base_table, bar_size, heartbeat)\n",
        "\n",
        "    #waiting for the tables to be populated\n",
        "    wait_for_tables(tickers, bar_size) #this is going to need to be rewritten\n",
        "    logger.info('Both price tables are currently present, script starting!')"
      ],
      "metadata": {
        "id": "ZwGAtoQ_8loJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_websockets(tickers, bar_size, ohlcv=False):\n",
        "    if ohlcv == True:\n",
        "        table_type = 'ohlcv_websockets'\n",
        "    else:\n",
        "        table_type = 'price_websockets'\n",
        "\n",
        "    current_time = int(time.time()*1000)\n",
        "\n",
        "    for t in tickers:\n",
        "        cloud.execute(\"UPDATE \" + str(table_type) + \" SET heartbeat=\"+ str(current_time) + \" WHERE ticker_name='\" + str(t) + \"' AND bar_size='\" + str(bar_size) + \"'\")\n",
        ""
      ],
      "metadata": {
        "id": "gUGR5_et8no9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ratios(tickers, use_crypto=False, modelling_bar_size=modelling_bar_size, modelling_duration=modelling_duration):\n",
        "\n",
        "    prices_hr = {}\n",
        "\n",
        "    if use_crypto == True:\n",
        "        for t in tickers:\n",
        "            prices_hr[t] = get_prices(t, modelling_bar_size, modelling_duration, use_crypto=use_crypto)\n",
        "    elif use_crypto == False:\n",
        "        for t in tickers:\n",
        "            prices_hr[t] = get_prices(t, modelling_bar_size, modelling_duration, use_crypto=use_crypto)\n",
        "\n",
        "    prices_df = pd.DataFrame(prices_hr)\n",
        "\n",
        "    jres = coint_johansen(prices_df, det_order=0, k_ar_diff=1)\n",
        "    coeff = jres.evec[:,0]\n",
        "\n",
        "    position_ratios = {}\n",
        "\n",
        "    for i in range(len(tickers)):\n",
        "        position_ratios[tickers[i]] = coeff[i]\n",
        "\n",
        "    return position_ratios"
      ],
      "metadata": {
        "id": "MRvPUvi18pNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_tables(data, tickers, position_ratios, use_crypto=False):\n",
        "\n",
        "    pair_number = data['pair_number']\n",
        "    bar_size = data['bar_size']\n",
        "\n",
        "    logger.info(\"Checking if appropriate sql tables exist and setting up hedge ratio! Creating tables that don't exist\")\n",
        "    table_list = ['current_data', 'trades', 'pair_data_' + str(pair_number), 'completed_trades', 'positions','trade_data_queue', 'equity_data', 'statuses', 'pair_trades', 'tickers', 'latest_prices'] #equity_data\n",
        "    to_create = []\n",
        "    create_cloud = []\n",
        "\n",
        "    for table in table_list:\n",
        "        res = cloud.execute(\"SELECT EXISTS ( SELECT FROM information_schema.tables WHERE table_name = '\" + table + \"');\")\n",
        "        a = res.one()[0]\n",
        "        if a == True:\n",
        "            pass\n",
        "        else:\n",
        "            create_cloud.append(table)\n",
        "\n",
        "    if len(to_create) > 0:\n",
        "        logger.info('Creating tables :' + str(to_create))\n",
        "\n",
        "    #tables need to be reformatted\n",
        "    for table in create_cloud:\n",
        "        if table == 'current_data':\n",
        "            cloud.execute(\"CREATE TABLE current_data (pair_number numeric, bar_size varchar(256), lookback numeric, current_z numeric, upper_band numeric, lower_band numeric, moving_average numeric, current_equity numeric, current_status varchar(256), total_pl numeric, raw_pl numeric, fees numeric, heartbeat numeric, spread numeric)\")\n",
        "            logger.info(f\"Creating table {table}\")\n",
        "\n",
        "        if table == 'trades':\n",
        "            cloud.execute(\"CREATE TABLE trades (pair_number numeric, internal_id numeric, trade_id numeric, timestamp varchar(256), ticker varchar(256), buy_sell varchar(256), price numeric, quantity numeric, fees numeric, status varchar(256))\")\n",
        "            logger.info(f\"Creating table {table}\")\n",
        "\n",
        "        if table == 'pair_data_' + str(pair_number):\n",
        "            cloud.execute(\"CREATE TABLE \" + table + \" (timestamp numeric, zscore numeric, upper_band numeric, lower_band numeric, moving_average numeric, spread numeric, equity numeric)\") #equity numeric\n",
        "            logger.info(f\"Creating table {table}\")\n",
        "\n",
        "        if table == 'completed_trades':\n",
        "            cloud.execute(\"CREATE TABLE completed_trades (pair_number numeric, ticker varchar(256), p_l numeric, fees numeric, close_time numeric, duration numeric, internal_id numeric, special_status varchar(256))\")\n",
        "            logger.info(f\"Creating table {table}\")\n",
        "\n",
        "        if table == 'tickers':\n",
        "            cloud.execute(\"CREATE TABLE tickers (pair_number numeric, ticker1 varchar(256),ticker2 varchar(256),ticker3 varchar(256),ticker4 varchar(256),ticker5 varchar(256),ticker6 varchar(256),ticker7 varchar(256),ticker8 varchar(256),ticker9 varchar(256),ticker10 varchar(256),ticker11 varchar(256),ticker12 varchar(256))\")\n",
        "            logger.info(f\"Creating table {table}\")\n",
        "        #this is going to need to be reworked\n",
        "        if table == 'positions':\n",
        "            cloud.execute(\"CREATE TABLE positions (pair_number numeric, pos_change_time numeric, script_update_time numeric, stop_flag bool, ticker1 numeric, ticker2 numeric,ticker3 numeric, ticker4 numeric,ticker5 numeric, ticker6 numeric, ticker7 numeric, ticker8 numeric, ticker9 numeric, ticker10 numeric, ticker11 numeric, ticker12 numeric)\")\n",
        "            logger.info(f\"Creating table {table}\")\n",
        "\n",
        "        if table == 'latest_prices':\n",
        "            cloud.execute(\"CREATE TABLE latest_prices (pair_number numeric, ticker1 numeric, ticker2 numeric,ticker3 numeric, ticker4 numeric,ticker5 numeric, ticker6 numeric, ticker7 numeric, ticker8 numeric, ticker9 numeric, ticker10 numeric, ticker11 numeric, ticker12 numeric)\")\n",
        "            logger.info(f\"Creating table {table}\")\n",
        "\n",
        "        if table == 'trade_data_queue':\n",
        "            cloud.execute(\"CREATE TABLE trade_data_queue (pair_number numeric, ticker varchar(256), quantity numeric, open_close varchar(256),shares_remaining numeric, timestamp numeric, internal_id numeric)\")\n",
        "            logger.info(f\"Creating table {table}\")\n",
        "\n",
        "        if table == 'equity_data':\n",
        "            cloud.execute(\"CREATE TABLE equity_data (timestamp numeric, equity numeric, unrealized_gains numeric)\")\n",
        "            logger.info(f\"Creating table {table}\")\n",
        "\n",
        "        if table == 'statuses':\n",
        "            cloud.execute(\"CREATE TABLE statuses (row numeric, display numeric, orders numeric, websockets numeric, unrealized numeric, latest_equity numeric)\")\n",
        "            logger.info(f\"Creating table {table}\")\n",
        "            cloud.execute(\"INSERT INTO statuses (row, display, orders, websockets) VALUES (1,0,0,0) \")\n",
        "\n",
        "        if table == 'pair_trades':\n",
        "            cloud.execute(\"CREATE TABLE pair_trades (pair_number numeric, internal_id numeric, pl numeric, fees numeric, total_pl numeric, latest_close_time numeric)\")\n",
        "            logger.info(f\"Creating table {table}\")\n",
        "\n",
        "    cloud.execute(\"DELETE FROM pair_data_\" + str(pair_number))\n",
        "\n",
        "    pos_table = cloud.execute(\"SELECT * FROM positions WHERE EXISTS (SELECT * FROM positions WHERE pair_number = \" + str(pair_number) + \")\")\n",
        "    pos_data = pos_table.all()\n",
        "\n",
        "    if len(pos_data) == 0:\n",
        "        cloud.execute(\"INSERT INTO positions (pair_number) VALUES (\" + str(pair_number) + \")\")\n",
        "\n",
        "    res = cloud.execute(\"SELECT * FROM positions WHERE pair_number=\" + str(pair_number)).fetchall()[0]\n",
        "    if res[7] == None or res[8] == None:\n",
        "\n",
        "        cloud.execute(\"UPDATE latest_prices SET ticker1=0, ticker2=0 ,ticker3=0, ticker4=0,ticker5=0, ticker6=0,ticker7=0, ticker8=0,ticker9=0, ticker10=0,ticker11=0, ticker12=0 WHERE pair_number=\" + str(pair_number))\n",
        "\n",
        "    #get all necessary info here, only doing the first 1000 bars to start\n",
        "\n",
        "    data = {}\n",
        "\n",
        "    if use_crypto == True:\n",
        "        for t in tickers:\n",
        "            data[t] = get_prices(t, bar_size, duration, use_crypto=True, return_all_data=True)\n",
        "    else:\n",
        "        for t in tickers:\n",
        "            data[t] = get_prices(t, bar_size_equity, duration_equity, use_crypto=False, return_all_data=True)\n",
        "\n",
        "    prices, timestamps = {}, []\n",
        "\n",
        "    if use_crypto == True:\n",
        "        for d in data:\n",
        "            prices[d] = [a[4] for a in data[d]]\n",
        "            timestamps = [a[0] for a in data[d]]\n",
        "    elif use_crypto == False:\n",
        "        for d in data:\n",
        "            prices[d] = [a.close for a in data[d]]\n",
        "            timestamps = [int(a.date.timestamp()) for a in data[d]]\n",
        "\n",
        "    spread = get_spread(position_ratios, prices)\n",
        "    spread = spread.values.tolist()\n",
        "    zscore, upper_band, lower_band, z_moving_avg = get_data(spread=spread)\n",
        "\n",
        "    spread, timestamps = spread[lookback*2+2:], timestamps[lookback*2+2:]\n",
        "    zscore, moving_avg, upper_band, lower_band = zscore[lookback*2+2:], z_moving_avg[lookback*2+2:], upper_band[lookback*2+2:], lower_band[lookback*2+2:]\n",
        "\n",
        "    data_list = []\n",
        "\n",
        "    for i in range(0,len(zscore)):\n",
        "        data_list.append({'timestamp':timestamps[i], 'zscore':zscore[i] , 'upper_band':upper_band[i], 'lower_band':lower_band[i], 'moving_average':moving_avg[i], 'spread':spread[i]})\n",
        "\n",
        "    table = Table(\"pair_data_\" + str(pair_number), meta, autoload=True, autoload_with=engine)\n",
        "    cloud.execute(table.insert(), data_list)\n",
        "\n",
        "    #create row in current_data if it does not exist.\n",
        "    res = cloud.execute(\"SELECT * FROM current_data WHERE EXISTS (SELECT * FROM current_data WHERE pair_number = \" + str(pair_number) + \")\")\n",
        "    data = res.all()\n",
        "\n",
        "    if len(data)==0:\n",
        "        cloud.execute(\"INSERT INTO current_data (pair_number) VALUES (6666666)\")\n",
        "\n",
        "#Crypto specific functions"
      ],
      "metadata": {
        "id": "1e75wpxh8tp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_global_data(tickers, data, position_ratios, global_data=[], use_crypto=False): #this is going to require some serious work to remain effective\n",
        "\n",
        "    duration = data['duration']\n",
        "    bar_size = data['bar_size']\n",
        "    global_data_max_size = data['global_data_max_size']\n",
        "\n",
        "    update, replace_df = False, False\n",
        "\n",
        "    if len(global_data) == 0:\n",
        "        logger.info('Global data is empty, initializing data!')\n",
        "        replace_df = True\n",
        "    else:\n",
        "\n",
        "        if use_crypto == True:\n",
        "\n",
        "            latest_time_pulled = get_prices_websocket(tickers[0], bar_size, 2, ohclv=False, return_all_data=True, use_crypto=use_crypto) #latest_time_pulled = get_prices_crypto(ticker1, bar_size, 2, return_all_data=True)\n",
        "            delta_time = int(abs((latest_time_pulled[0][0] - latest_time_pulled[1][0])/1000)) #in seconds\n",
        "\n",
        "            latest_df_time = global_data['Time'].iloc[0]\n",
        "            differential = latest_time_pulled[0][0]- latest_df_time\n",
        "            if differential > 0:\n",
        "\n",
        "                delta_bars = ((latest_time_pulled[0][0] - latest_df_time)/(delta_time*1000))*1.2\n",
        "                if delta_bars > len(global_data):\n",
        "                    replace_df = True #update entire dataframe\n",
        "\n",
        "            elif differential == 0:\n",
        "                update = True\n",
        "\n",
        "        else:\n",
        "\n",
        "            latest_time_pulled = get_prices(tickers[0], bar_size, 2, return_all_data=True, use_crypto=use_crypto) #how do we onlu\n",
        "            delta_time = int(abs((latest_time_pulled[0][0] - latest_time_pulled[1][0])/1000)) #in seconds\n",
        "\n",
        "            latest_df_time = global_data['Time'].iloc[0]\n",
        "            differential = latest_time_pulled[0][0]- latest_df_time\n",
        "            if differential > 0:\n",
        "\n",
        "                delta_bars = ((latest_time_pulled[0][0] - latest_df_time)/(delta_time*1000))*1.2\n",
        "                if delta_bars > len(global_data):\n",
        "                    replace_df = True #update entire dataframe\n",
        "\n",
        "            elif differential == 0:\n",
        "                update = True\n",
        "\n",
        "    data_latest = {}\n",
        "\n",
        "    times = []\n",
        "    data_close = {}\n",
        "    data_low = {}\n",
        "    data_high = {}\n",
        "    volume = {}\n",
        "    volume_ma = {}\n",
        "\n",
        "    if use_crypto == True:\n",
        "\n",
        "        for t in tickers:\n",
        "            data = get_prices_websocket(t, bar_size, duration, ohclv=True, return_all_data=True, use_crypto=use_crypto)[:global_data_max_size]\n",
        "            data = data[::-1]\n",
        "            data_latest[t] = data\n",
        "\n",
        "        times = [d[0] for d in data]\n",
        "\n",
        "        for t in tickers:\n",
        "            data_close[t] = [t[4] for t in data[t]]\n",
        "            data_low[t] = [t[3] for t in data[t]]\n",
        "            data_high[t] = [t[2] for t in data[t]]\n",
        "\n",
        "    else:\n",
        "\n",
        "        for t in tickers:\n",
        "            data = get_prices(t, bar_size, duration, return_all_data=True, use_crypto=False)[:global_data_max_size]\n",
        "            data = data[::-1]\n",
        "            data_latest[t] = data\n",
        "\n",
        "        times = [d[0] for d in data]\n",
        "\n",
        "        for t in tickers:\n",
        "            data_close[t] = [t.close for t in data[t]]\n",
        "            data_low[t] = [t.low for t in data[t]]\n",
        "            data_high[t] = [t.high for t in data[t]]\n",
        "\n",
        "    spread = get_spread(position_ratios, global_data=global_data) #this needs to be looked at\n",
        "\n",
        "    zscore, upper_band, lower_band, moving_avg = get_data(spread=spread) #this needs to be looked at\n",
        "\n",
        "    #reverse prices here...may need to be reversed for equities as well.\n",
        "\n",
        "    spread, zscore, upper_band, lower_band, moving_avg = spread[::-1], zscore[::-1], upper_band[::-1], lower_band[::-1], moving_avg[::-1]\n",
        "\n",
        "    df = pd.DataFrame({'Time':times,'Spread': spread,'Zscore': zscore, 'Upper Band': upper_band, 'Lower Band': lower_band, 'Moving Average': moving_avg})\n",
        "\n",
        "    for t in tickers: #add to the df dataframe\n",
        "        df[f'Ticker {t} Price'] = data_close[t]\n",
        "\n",
        "    if update == True:\n",
        "        global_data.iloc[0] = df.iloc[0]\n",
        "\n",
        "    elif replace_df == False and update == False:\n",
        "        df_time = df['Time'].iloc[-1]\n",
        "        rows = 0\n",
        "        for t in global_data['Time']:\n",
        "            rows += 1\n",
        "            if df_time == t:\n",
        "                break\n",
        "        if rows > 0:\n",
        "            global_data = global_data.truncate(before=rows)\n",
        "            global_data = pd.merge(df,global_data, how=\"outer\")\n",
        "\n",
        "    elif replace_df == True:\n",
        "        global_data = df\n",
        "\n",
        "    if len(global_data) < lookback * 2.2: #this should solve any issues that we have with this. If the length is too short we just replace it.\n",
        "        global_data = df\n",
        "        logger.error('Replacing df -- error 11')\n",
        "\n",
        "    global_data = global_data[:global_data_max_size]\n",
        "\n",
        "    return global_data"
      ],
      "metadata": {
        "id": "jBG3ll4T8w0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prices(ticker, bar_period,bars_back,return_all_data=False, use_crypto=False):\n",
        "\n",
        "    prices = []\n",
        "\n",
        "    if use_crypto == True:\n",
        "\n",
        "        if bars_back <= 1000:\n",
        "                data = exchange.fetch_ohlcv(ticker,bar_period,limit=bars_back)\n",
        "\n",
        "        elif bars_back > 1000: #***finish this for pagenation, how do we get a certain period?\n",
        "            date_list, data = [], []\n",
        "            if bar_period == '1m':\n",
        "                time_delta = 60\n",
        "            elif bar_period == '5m':\n",
        "                time_delta = 60*5\n",
        "            elif bar_period == '15m':\n",
        "                time_delta = 60*15\n",
        "            elif bar_period == '30m':\n",
        "                time_delta = 60*30\n",
        "            elif bar_period == '1h':\n",
        "                time_delta = 60*60\n",
        "            elif bar_period == '2h':\n",
        "                time_delta = 60*120\n",
        "            elif bar_period == '4h':\n",
        "                time_delta = 60*4*60\n",
        "            elif bar_period == '6h':\n",
        "                time_delta = 60*6*60\n",
        "            else:\n",
        "                logger.error('Please enter an appropriate time period or add the timedelta!')\n",
        "                print(Break123)\n",
        "\n",
        "            now = int(time.time()*1000)\n",
        "            res = math.floor(bars_back/1000)\n",
        "\n",
        "            for i in range(1,res+1):\n",
        "                date_list.append(now-(time_delta*i*1000*1000))\n",
        "\n",
        "            date_list = date_list[::-1]\n",
        "            for date in date_list:\n",
        "                data = data + exchange.fetch_ohlcv(ticker,bar_period,since=date,limit=1000)\n",
        "\n",
        "        if return_all_data == True:\n",
        "            return data\n",
        "        else:\n",
        "\n",
        "            for d in data:\n",
        "                prices.append(d[4])\n",
        "            return prices\n",
        "\n",
        "    else:\n",
        "\n",
        "        stock = Stock(ticker, 'SMART', 'USD')\n",
        "        data = ib.reqHistoricalData(stock, endDateTime='', durationStr=bars_back, barSizeSetting=bar_period, whatToShow='BID', useRTH=True)\n",
        "\n",
        "        if return_all_data == False:\n",
        "            for d in data:\n",
        "                prices.append(d.close)\n",
        "\n",
        "            return prices\n",
        "\n",
        "        if return_all_data == True:\n",
        "            return data"
      ],
      "metadata": {
        "id": "8NUzgjAY8z5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prices_websocket(tickers, bar_size, bars, ohclv=False, return_all_data=False, use_crypto=False): #this is going to be the one we want to use next, and going to require some further editing\n",
        "    if use_crypto == True:\n",
        "        ticker = format_tickers(tickers)\n",
        "        table = 'ohlcv_' + str(ticker).lower() + '_' + str(bar_size)\n",
        "        if return_all_data == False:\n",
        "            res = pd.DataFrame(cloud.execute(\"SELECT close FROM \" + str(table) + \" ORDER BY timestamp desc\").all())['close'].values.tolist()\n",
        "            return res[:bars] #results are returned most recent bar first\n",
        "        else:\n",
        "            res = pd.DataFrame(cloud.execute(\"SELECT * FROM \" + str(table) + \" ORDER BY timestamp desc\").all()).values.tolist()\n",
        "            return res[:bars]\n",
        "    else:\n",
        "        pass\n",
        "        #function to get websocket data from interactive brokers"
      ],
      "metadata": {
        "id": "KPQy4vom81DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_entry_signals(global_data): #this is on hold until the rest of the script is working with multivariate\n",
        "\n",
        "    if volume_signal == True:\n",
        "\n",
        "        last_bars_vol = {}\n",
        "\n",
        "        last_5bars_vol_a = max(global_data['Volume A'].iloc[:5].values.tolist())\n",
        "        last_5bars_vol_b = max(global_data['Volume B'].iloc[:5].values.tolist())\n",
        "\n",
        "        vol_ma = {}\n",
        "\n",
        "        vol_ma_a = get_moving_avg(global_data['Volume A'][::-1], override='sma')['Volume A'].values.tolist()\n",
        "        vol_ma_b = get_moving_avg(global_data['Volume B'][::-1], override='sma')['Volume B'].values.tolist()\n",
        "\n",
        "        if vol_notrade_multiple*vol_ma_a[-1] < last_5bars_vol_a or vol_notrade_multiple*vol_ma_b[-1] < last_5bars_vol_b:\n",
        "            return False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "4Qvvx9Ld82I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialization(tickers, data, current_state, last_pos, use_crypto, pair_number,  bar_size):\n",
        "    logger.info(f'Starting Script for pair {pair_number}! Running pre-initialization functions!')\n",
        "\n",
        "    if use_crypto == True:\n",
        "        tickers = format_tickers(tickers)\n",
        "\n",
        "    position_ratios = get_ratios(tickers, use_crypto = use_crypto)\n",
        "    check_tables(data, tickers, position_ratios, use_crypto=use_crypto)\n",
        "    if use_crypto == True:\n",
        "        check_websockets(data, tickers, bar_size, ohlcv=ohlcv)\n",
        "    global_data = update_global_data(tickers,data, position_ratios, use_crypto=use_crypto) #this needs quite a bit of work\n",
        "    current_state = get_current_state(data)\n",
        "    new_quantities = get_quantities(tickers, global_data, data, position_ratios)\n",
        "    internal_id = set_positions_database(internal_id, tickers, new_quantities, None, current_state,data,use_crypto=use_crypto) #needs a little bit of work\n",
        "    logger.info('Starting pair ' + str(pair_number))\n",
        "\n",
        "    return formatted_tickers, position_ratios, global_data, current_state, new_quantities, internal_id"
      ],
      "metadata": {
        "id": "8lfTqO8d83Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loop(tickers, data, current_state=current_state, last_pos=last_pos, use_crypto=False):\n",
        "\n",
        "    entry_signal_flag = True\n",
        "    internal_id = 100000\n",
        "    reset_flag = False\n",
        "    pair_number = data['pair_number']\n",
        "    bar_size = data['bar_size']\n",
        "\n",
        "    formatted_tickers, position_ratios, global_data, current_state, new_quantities, internal_id = initialization(tickers, data, current_state, last_pos, use_crypto, pair_number, bar_size)\n",
        "\n",
        "    while True:\n",
        "        global_data = update_global_data(tickers, data, position_ratios, global_data=global_data)\n",
        "\n",
        "        curr_zscore, curr_moving_avg, curr_upper_band, curr_lower_band = global_data['Zscore'].iloc[0], global_data['Moving Average'].iloc[0], global_data['Upper Band'].iloc[0], global_data['Lower Band'].iloc[0]\n",
        "\n",
        "        if use_stoploss == True:\n",
        "            internal_id = check_exit_conditions(internal_id, global_data, tickers, new_quantities,current_state, data, percent_stop=True)\n",
        "\n",
        "        prior_state = current_state\n",
        "\n",
        "        current_state, reset_flag, trade_status = decide_positions(curr_zscore, curr_moving_avg, curr_upper_band, curr_lower_band,reset_flag, current_state)\n",
        "\n",
        "        if prior_state != None:\n",
        "            prior_state = prior_state.lower()\n",
        "        if current_state != None:\n",
        "            current_state = current_state.lower()\n",
        "\n",
        "        if current_state == None:\n",
        "            #for now we will only avoid entering new trades\n",
        "            entry_signal_flag = check_entry_signals(global_data)\n",
        "\n",
        "        if (prior_state != current_state) and reset_flag == False:\n",
        "            if prior_state == None and entry_signal_flag == False:\n",
        "                logger.info('Trade averted due to entry signal flag being false')\n",
        "\n",
        "            else:\n",
        "                logger.info(f\"Position has changed, submitting trades. The current state is {current_state} and the previous state is {prior_state}\")\n",
        "                internal_id = set_positions_database(internal_id, tickers, new_quantities, prior_state, current_state,data,use_crypto=True)\n",
        "\n",
        "        record_data(data, tickers, current_state, global_data, use_crypto=use_crypto)\n",
        "\n",
        "        if use_crypto == true:\n",
        "            update_websockets(formatted_tickers, bar_size,ohlcv=ohlcv)\n",
        "\n",
        "        time.sleep(0.5)"
      ],
      "metadata": {
        "id": "JYs9hcOx85b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Required -- Pair Number, tickers, Lookback Period (reference only), Bar Size, Spread Lookback Period (Operational), Std Dev\n",
        "def start(pair_number1, tickers, bar_size, lookback,sigma,order_val_input=total_order_value, avg_type_input=average_type,stop_loss=max_loss,stoploss_break=break_on_loss, band_vol_exp=bollinger_vol_exp, bol_band_type=bollinger_type, use_crypto=False):\n",
        "    data = {}\n",
        "\n",
        "    data['pair_number'] = pair_number1 # pair_number = pair_number1\n",
        "    data['duration'] = lookback*5 #duration_lookback = lookback_input*5\n",
        "    data['bar_size'] = bar_size #bar_size = bar_size\n",
        "    data['lookback'] = lookback #lookback = lookback_input\n",
        "    data['entry_sigma '] = sigma #entry_sigma = sigma\n",
        "    data['total_order_value'] = order_val_input #total_order_value = order_val_input\n",
        "    data['average_type'] = avg_type_input #average_type = avg_type_input\n",
        "    data['max_loss'] = stop_loss #max_loss = stop_loss\n",
        "    data['break_on_loss'] = stoploss_break #break_on_loss = stoploss_break\n",
        "    data['bollinger_vol_exp'] = band_vol_exp # bollinger_vol_exp = band_vol_exp\n",
        "    data['bollinger_type'] = bol_band_type #bollinger_type = bol_band_type\n",
        "\n",
        "    if use_crypto == True:\n",
        "        data['global_data_max_size'] = int(float(lookback)*2.5) #global_data_max_size = int(float(lookback)*2.5) #max size of global_data\n",
        "    else:\n",
        "        data['global_data_max_size'] = 300\n",
        "\n",
        "    loop(tickers, data, use_crypto=use_crypto)\n"
      ],
      "metadata": {
        "id": "_JvIZsad6XOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    tickers = ['PLTR', 'AI']\n",
        "    start(1, tickers, '1 hour', '5 D', 2, use_crypto=crypto)"
      ],
      "metadata": {
        "id": "zmFGD2uK88AV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}